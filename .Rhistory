recalls3[i] <- tp / (tp + fn)
}
mean_precision3 <- mean(precisions3, na.rm = TRUE)
mean_recall3 <- mean(recalls3, na.rm = TRUE)
mean_accuracy3 <- mean(accuracies3)
mean_precision3
mean_recall3
mean_accuracy3
print(paste("Mean Precision:", mean_precision3))
print(paste("Mean Recall:", mean_recall3))
print(paste("Mean Accuracy:", mean_accuracy3))
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
auc_value_binary <- auc(roc_obj_binary)
print(paste("AUC (Binary):", auc_value_binary))
mean_accuracy1
mean_precision1
mean_recall1
# 绘制ROC曲线
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
precisions1 <- numeric(length(beta1$V1))
recalls1 <- numeric(length(beta1$V1))
accuracies1 <- numeric(length(beta1$V1))
for (i in 1:length(beta1$V1)) {
df$y_hat <- beta1[i,1] + beta1[i,2] * df$gender + beta1[i,3] * df$race + beta1[i,4] * df$age +
beta1[i,5] * df$mhv1 + beta1[i,6] * df$mhv2 + beta1[i,7] * df$mhv3 + beta1[i,8] * df$inptmhv + ui[i]
df$mu_hat <- ifelse(df$y_hat < 0, 0, 1)
accuracy <- mean(df$polypharm == df$mu_hat)
accuracies1[i] <- accuracy
tp <- sum(df$mu_hat == 1 & df$polypharm == 1)
fp <- sum(df$mu_hat == 1 & df$polypharm == 0)
fn <- sum(df$mu_hat == 0 & df$polypharm == 1)
precisions1[i] <- tp / (tp + fp)
recalls1[i] <- tp / (tp + fn)
}
mean_precision1 <- mean(precisions1, na.rm = TRUE)
mean_recall1 <- mean(recalls1, na.rm = TRUE)
mean_accuracy1 <- mean(accuracies1)
mean_accuracy1
mean_precision1
mean_recall1
print(paste("Mean Precision:", mean_precision1))
print(paste("Mean Recall:", mean_recall1))
print(paste("Mean Accuracy:", mean_accuracy1))
actual <- df$polypharm
predicted_prob <- df$mu_hat
# 检查实际标签和预测概率
table(actual)  # 确保是二分类标签
summary(predicted_prob)  # 确保是[0, 1]之间的概率值
# 生成ROC对象
roc_obj_binary <- roc(actual, predicted_prob)
# 绘制ROC曲线
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
# 计算AUC值
auc_value_binary <- auc(roc_obj_binary)
print(paste("AUC (Binary):", auc_value_binary))
table
table(df$mu_hat)
roc_obj_binary <- roc(df$mu_hat, df$polypharm)
# ROC
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
roc_obj_binary <- roc(df$mu_hat, df$polypharm)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
# 计算ROC曲线
roc_obj <- roc(actual, predicted_prob, levels = c(0, 1), direction = "<")
# 获取AUC值
auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))
# 绘制ROC曲线
plot(roc_obj, main = "ROC Curve using Binary Predictions", col = "darkorange", lwd = 2)
abline(a = 0, b = 1, col = "navy", lty = 2, lwd = 2)  # 绘制对角线
# 计算ROC曲线
roc_obj <- roc(actual, predicted_prob, levels = c(0, 1), direction = ">")
# 获取AUC值
auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))
# 绘制ROC曲线
plot(roc_obj, main = "ROC Curve using Binary Predictions", col = "darkorange", lwd = 2)
# 计算ROC曲线
roc_obj <- roc(actual, predicted_prob, levels = c(1,0), direction = "<")
# 获取AUC值
auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))
# 绘制ROC曲线
plot(roc_obj, main = "ROC Curve using Binary Predictions", col = "darkorange", lwd = 2)
abline(a = 0, b = 1, col = "navy", lty = 2, lwd = 2)  # 绘制对角线
####### chain 3 #######
precisions3 <- numeric(length(beta3$V1))
recalls3 <- numeric(length(beta3$V1))
accuracies3 <- numeric(length(beta3$V1))
for (i in 1:length(beta3$V1)) {
df$y_hat <- beta3[i,1] + beta3[i,2] * df$gender + beta3[i,3] * df$race + beta3[i,4] * df$age +
beta3[i,5] * df$mhv1 + beta3[i,6] * df$mhv3 + beta3[i,7] * df$mhv3 + beta3[i,8] * df$inptmhv + ui[i]
df$mu_hat <- ifelse(df$y_hat < 0, 0, 1)
accuracy <- mean(df$polypharm == df$mu_hat)
accuracies3[i] <- accuracy
tp <- sum(df$mu_hat == 1 & df$polypharm == 1)
fp <- sum(df$mu_hat == 1 & df$polypharm == 0)
fn <- sum(df$mu_hat == 0 & df$polypharm == 1)
precisions3[i] <- tp / (tp + fp)
recalls3[i] <- tp / (tp + fn)
}
mean_precision3 <- mean(precisions3, na.rm = TRUE)
mean_recall3 <- mean(recalls3, na.rm = TRUE)
mean_accuracy3 <- mean(accuracies3)
mean_precision3
mean_recall3
mean_accuracy3
print(paste("Mean Precision:", mean_precision3))
print(paste("Mean Recall:", mean_recall3))
print(paste("Mean Accuracy:", mean_accuracy3))
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
auc_value_binary <- auc(roc_obj_binary)
print(paste("AUC (Binary):", auc_value_binary))
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
abline(a = 0, b = 1, col = "navy", lty = 2, lwd = 2)  # 绘制对角线
auc_value_binary
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
mean_precision3
mean_recall3
mean_accuracy3
table(df$mu_hat)
precisions1 <- numeric(length(beta1$V1))
recalls1 <- numeric(length(beta1$V1))
accuracies1 <- numeric(length(beta1$V1))
for (i in 1:length(beta1$V1)) {
df$y_hat <- beta1[i,1] + beta1[i,2] * df$gender + beta1[i,3] * df$race + beta1[i,4] * df$age +
beta1[i,5] * df$mhv1 + beta1[i,6] * df$mhv2 + beta1[i,7] * df$mhv3 + beta1[i,8] * df$inptmhv + ui[i]
df$mu_hat <- ifelse(df$y_hat < 0, 0, 1)
accuracy <- mean(df$polypharm == df$mu_hat)
accuracies1[i] <- accuracy
tp <- sum(df$mu_hat == 1 & df$polypharm == 1)
fp <- sum(df$mu_hat == 1 & df$polypharm == 0)
fn <- sum(df$mu_hat == 0 & df$polypharm == 1)
precisions1[i] <- tp / (tp + fp)
recalls1[i] <- tp / (tp + fn)
}
mean_precision1 <- mean(precisions1, na.rm = TRUE)
mean_recall1 <- mean(recalls1, na.rm = TRUE)
mean_accuracy1 <- mean(accuracies1)
mean_accuracy1
mean_precision1
mean_recall1
print(paste("Mean Precision:", mean_precision1))
print(paste("Mean Recall:", mean_recall1))
print(paste("Mean Accuracy:", mean_accuracy1))
actual <- df$polypharm
predicted_prob <- df$mu_hat
# ROC
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
# AUC
auc_value_binary <- auc(roc_obj_binary)
print(paste("AUC (Binary):", auc_value_binary))
mean_accuracy1
mean_precision1
mean_recall1
table(df$mu_hat)
beta <- read.csv('sample.csv')
ui <- read.csv('u_i.csv')
#ui <- ui[2501:5000,-501]
ui <- as.data.frame(t(ui))
ui <- ui[rep(1:nrow(ui), each = 7), ]
ui <- cbind(ui, ui, ui, ui, ui, ui, ui, ui, ui, ui)
df <- polypharm[, c(2, 11, 12, 14)]
df$polypharmacy <- ifelse(df$polypharmacy == 'No', 0, 1)
df$gender <- ifelse(df$gender == 'Male', 1, 0)
df$race <- ifelse(df$race == 'White', 0, 1)
df$mhv1 <- ifelse(polypharm$mhv4 == '1-5', 1, 0)
df$mhv2 <- ifelse(polypharm$mhv4 == '6-14', 1, 0)
df$mhv3 <- ifelse(polypharm$mhv4 == '> 14', 1, 0)
df$inptmhv <- ifelse(polypharm$inptmhv3 == 0, 0, 1)
precisions <- numeric(length(beta$V1))
recalls <- numeric(length(beta$V1))
accuracies <- numeric(length(beta$V1))
for (i in 1:length(beta$V1)) {
df$y_hat <- beta[i,1] + beta[i,2] * df$gender + beta[i,3] * df$race + beta[i,4] * df$age +
beta[i,5] * df$mhv1 + beta[i,6] * df$mhv2 + beta[i,7] * df$mhv3 + beta[i,8] * df$inptmhv + ui[i]
df$mu_hat <- ifelse(df$y_hat < 0, 0, 1)
accuracy <- mean(df$polypharm == df$mu_hat)
accuracies[i] <- accuracy
tp <- sum(df$mu_hat == 1 & df$polypharm == 1)
fp <- sum(df$mu_hat == 1 & df$polypharm == 0)
fn <- sum(df$mu_hat == 0 & df$polypharm == 1)
precisions[i] <- tp / (tp + fp)
recalls[i] <- tp / (tp + fn)
}
mean_precision <- mean(precisions, na.rm = TRUE)
mean_recall <- mean(recalls, na.rm = TRUE)
mean_accuracy <- mean(accuracies)
mean_accuracy
mean_precision
mean_recall
actual <- df$polypharm
predicted_prob <- df$mu_hat
# ROC
roc_obj_binary <- roc(df$polypharm, df$mu_hat)
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
# AUC
auc_value_binary <- auc(roc_obj_binary)
print(paste("AUC (Binary):", auc_value_binary))
plot(roc_obj_binary, main = "ROC Curve using Binary Predictions", col = "red", lwd = 2)
mean_accuracy
mean_precision
mean_recall
table(df$mu_hat)
library(lme4)
library(lme4)
model <- glmer(response ~ fixed_effect + (1 | group), data = df, family = binomial)
library(aplore3)
library(ROCR)
library(e1071)
library(MASS)
library(pROC)
library(caret)
data(polypharm)
df <- polypharm[, c(2, 11, 12, 14)]
df$polypharmacy <- ifelse(df$polypharmacy == 'No', 0, 1)
df$gender <- ifelse(df$gender == 'Male', 1, 0)
df$race <- ifelse(df$race == 'White', 0, 1)
df$mhv1 <- ifelse(polypharm$mhv4 == '1-5', 1, 0)
df$mhv2 <- ifelse(polypharm$mhv4 == '6-14', 1, 0)
df$mhv3 <- ifelse(polypharm$mhv4 == '> 14', 1, 0)
df$inptmhv <- ifelse(polypharm$inptmhv3 == 0, 0, 1)
View(df)
ui <- read.csv('u_i.csv')
#ui <- ui[2501:5000,-501]
ui <- as.data.frame(t(ui))
ui <- ui[rep(1:nrow(ui), each = 7), ]
ui <- cbind(ui, ui, ui, ui, ui, ui, ui, ui, ui, ui)
model <- glmer(polypharm$polypharmacy ~ df$gender + df$race + df$age + df$mhv1 + df$mhv2 + df$mhv3 + df$inptmhv
+ (1 | ui$V1), data = df, family = binomial)
# 进行预测，获取预测概率
predicted_prob <- predict(model, df, type = "response")
# 将预测概率转换为二分类预测
predicted_class <- ifelse(predicted_prob > 0.5, 1, 0)
# 计算混淆矩阵
confusion_matrix <- confusionMatrix(factor(predicted_class), factor(df$polypharmacy))
# 提取准确率、召回率和精确率
accuracy <- confusion_matrix$overall['Accuracy']
recall <- confusion_matrix$byClass['Sensitivity']
precision <- confusion_matrix$byClass['Precision']
# 打印结果
print(paste("Accuracy:", accuracy))
print(paste("Recall:", recall))
print(paste("Precision:", precision))
accuracy
recall
precision
confusion_matrix
# 计算ROC曲线
roc_obj <- roc(df$polypharmacy, predicted_prob)
# 获取AUC值
auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))
# 绘制ROC曲线
plot(roc_obj, main = "ROC Curve", col = "darkorange", lwd = 2)
# 绘制ROC曲线
plot(roc_obj, main = "ROC Curve", col = "red", lwd = 2)
accuracy
recall
precision
table(predicted_class)
summary(model)
View(polypharm)
table
table(polypharm$polypharmacy)
library(aplore3)
data <- polypharm
data$gender <- ifelse(polypharm$gender=="Male",1,0)
data$racewhite <- ifelse(polypharm$race=="White",1,0)
data$MHV1 <- ifelse(polypharm$mhv4=="1-5",1,0)
data$MHV2 <- ifelse(polypharm$mhv4=="6-14",1,0)
data$MHV3 <- ifelse(polypharm$mhv4=="> 14",1,0)
data$INPTMHV <- ifelse(polypharm$inptmhv3=="0",0,1)
library(dplyr)
data <- select(data, select=c(gender, racewhite, age, MHV1, MHV2, MHV3, INPTMHV))
colnames(data) <- c("gender", "racewhite", "age", "MHV1", "MHV2", "MHV3", "INPTMHV")
polypharmacy <- ifelse(polypharm$polypharmacy=="Yes",1,0)
model<-glm(polypharm$polypharmacy~gender+racewhite+age+MHV1+MHV2+MHV3+INPTMHV,family= binomial, data = data)
summary(model)
# Logit function
logit <- function(p) {
log(p / (1 - p))
}
# Logistic function
inv_logit <- function(x) {
exp(x) / (1 + exp(x))
}
# Log-likelihood function
log_likelihood <- function(beta, u, sigma_u) {
#beta <- beta[1,]
#u <- u[1,]
#sigma_u <- sigma_u_init
log_lik <- 0
for (n in 1:3500) {
eta <- sum(data[n, ] * beta[2:8]) + beta[1] + u[polypharm$id[n]]
p <- inv_logit(eta)
if(p<-10000) return (0)
log_lik <- log_lik + polypharmacy[n] * log(p) + (1 - polypharmacy[n]) * log(1 - p)
}
#log_lik <- log_lik - sum(u^2) / (2 * sigma_u^2)
return(log_lik)
}
# Prior function
log_prior <- function(beta, sigma_u) {
sum(dnorm(beta, 0, 10, log = TRUE)) + dnorm(sigma_u, 0, 10, log = TRUE)
}
# Posterior function
log_posterior <- function(beta, u, sigma_u) {
log_prior(beta, sigma_u) + log_likelihood(beta, u, sigma_u)
}
set.seed(1234)
# Metropolis-Hastings algorithm
metropolis_hastings <- function(iter, beta_init, u_init, sigma_u_init, proposal_sd) {
# Initialize variables
#
beta <- matrix(NA, nrow = iter, ncol = length(beta_init))
u <- matrix(NA, nrow = iter, ncol = length(u_init))
sigma_u <- matrix(NA, nrow = iter, ncol = length(sigma_u_init))
beta[1, ] <- beta_init
u[1, ] <- u_init
sigma_u[1, ] <- sigma_u_init
lpnow <- log_posterior(beta_init, u_init, sigma_u_init)
#proposal_sd <- 10
for (t in 2:iter) {
print(t)
# Propose new values
beta_prop <- beta[t-1, ] + rnorm(length(beta_init), 0, proposal_sd)
sigma_u_prop <- sigma_u[t-1, ] + rnorm(1, 0, proposal_sd)
u_prop <- rnorm(500,0,exp(sigma_u_prop))
lplast <- lpnow
lpnow <- log_posterior(beta_prop, u_prop, sigma_u_prop)
# Compute acceptance probability
log_alpha <- lpnow-lplast
alpha <- exp(log_alpha)
# Accept or reject proposal
if (runif(1) < alpha) {
beta[t, ] <- beta_prop
u[t, ] <- u_prop
sigma_u[t, ] <- sigma_u_prop
} else {
beta[t, ] <- beta[t-1, ]
u[t, ] <- u[t-1, ]
sigma_u[t] <- sigma_u[t-1]
}
}
return(list(beta = beta, u = u, sigma_u = sigma_u))
}
# Set initial values and parameters
J <- 500
beta_init <- model$coefficients
sigma_u_init <- rnorm(1,0,10)
u_init <- rnorm(J,0,exp(sigma_u_init))
proposal_sd <- 0.1
iter <- 50
# Run Metropolis-Hastings algorithm
results <- metropolis_hastings(iter, beta_init, u_init, sigma_u_init, proposal_sd)
# Extract samples
beta_samples <- results$beta
u_samples <- results$u
sigma_u_samples <- results$sigma_u
write.csv(results,file = "results.csv")
library(coda)
results<-read.csv("results.csv")
beta_samples <- cbind(results$beta.1,results$beta.2,results$beta.3,results$beta.4,results$beta.5,results$beta.6,results$beta.7,results$beta.8)
# Define a function to plot trace plot, acf plot, and R statistic
plot_mcmc_diagnostic <- function(beta_samples) {
# Extract MCMC samples
#u_samples <- results$u
#sigma_u_samples <- results$sigma_u
par(mfrow=c(3,3))
# Trace plot
for (param in 1:ncol(beta_samples)) {
plot(beta_samples[, param], type = "l", ylab = paste("beta[", param, "]"), col = "blue")
}
par(mfrow=c(3,3))
# ACF plot
for (param in 1:ncol(beta_samples)) {
acf(beta_samples[, param], main = paste("ACF of beta[", param, "] "), col = "blue",xlim=c(1,50))
}
par(mfrow=c(3,3))
# histogram plot
for (param in 1:ncol(beta_samples)) {
hist(beta_samples[, param], main = paste("Histogram of beta[", param, "] "), col = "blue")
}
# Gelman-Rubin statistic
#gr_diag_beta <- gelman.diag(beta_samples)
#gr_diag_u <- gelman.diag(u_samples)
#gr_diag_sigma_u <- gelman.diag(sigma_u_samples)
#cat("Gelman-Rubin diagnostics for beta:\n")
#print(gr_diag_beta)
#cat("\nGelman-Rubin diagnostics for u:\n")
#print(gr_diag_u)
#cat("\nGelman-Rubin diagnostics for sigma_u:\n")
#print(gr_diag_sigma_u)
}
# Run the function with your MCMC results
iter <- 2500
beta_samples <- beta_samples[(iter/2+1):iter,]
metropolis_hastings_multiple <- function(iter, beta_init, u_init, sigma_u_init, proposal_sd) {
set.seed(1234)
# Number of chains
num_chains <- 4
cold_chains <- 3
hot_chain <- 1
# Initialize variables
beta <- array(NA, dim = c(iter, length(beta_init), num_chains))
u <- array(NA, dim = c(iter, length(u_init), num_chains))
sigma_u <- array(NA, dim = c(iter, length(sigma_u_init), num_chains))
for (chain in 1:num_chains) {
beta[1, , chain] <- beta_init
u[1, , chain] <- u_init
sigma_u[1, , chain] <- sigma_u_init
}
lpnow <- sapply(1:num_chains, function(chain) log_posterior(beta_init, u_init, sigma_u_init))
lplast <- lpnow
for (t in 2:iter) {
print(t)
for (chain in 1:num_chains) {
# Propose new values
beta_prop <- beta[t-1, , chain] + rnorm(length(beta_init), 0, proposal_sd)
sigma_u_prop <- sigma_u[t-1, , chain] + rnorm(1, 0, proposal_sd)
u_prop <- rnorm(500, 0, exp(sigma_u_prop))
lplast[chain] <- lpnow[chain]
lpnow[chain] <- log_posterior(beta_prop, u_prop, sigma_u_prop)
# Compute acceptance probability
log_alpha <- lpnow[chain] - lplast[chain]
# Adjust acceptance probability for the hot chain
if (chain == hot_chain) {
log_alpha <- log_alpha / 2
}
alpha <- exp(log_alpha)
# Accept or reject proposal
if (runif(1) < alpha) {
beta[t, , chain] <- beta_prop
u[t, , chain] <- u_prop
sigma_u[t, , chain] <- sigma_u_prop
} else {
beta[t, , chain] <- beta[t-1, , chain]
u[t, , chain] <- u[t-1, , chain]
sigma_u[t, , chain] <- sigma_u[t-1, , chain]
}
}
}
return(list(beta = beta, u = u, sigma_u = sigma_u))
}
# Set initial values and parameters
J <- 500
beta_init <- model$coefficients
sigma_u_init <- rnorm(1, 0, 10)
u_init <- rnorm(J, 0, exp(sigma_u_init))
proposal_sd <- 10
iter <- 1000
# Run Metropolis-Hastings algorithm
results <- metropolis_hastings_multiple(iter, beta_init, u_init, sigma_u_init, proposal_sd)
for(chain in 1:4) plot_mcmc_diagnostic(results$beta[, ,chain])
# 假设结果存在 results$beta[, , chain] 中，n 是结果的迭代次数
half_n <- ceiling(iter / 2)
# 提取后半部分结果
converged_results <- results$beta[(half_n+1):iter, , ]
# 计算每个参数的平均值
chain_means <- apply(converged_results, 2, function(x) colMeans(x))
# 计算每个参数的全局平均值
overall_means <- colMeans(chain_means)
# 计算每个参数在每条链上的方差
chain_vars <- apply(converged_results, 3, var)
# 计算每个参数的全局方差
overall_vars <- colMeans(chain_vars)
# 计算收敛因子
potential_scale_reduction <- sqrt(overall_vars / chain_vars)
# 判断MCMC是否收敛
if (all(potential_scale_reduction < 1.1)) {
print("MCMC收敛")
} else {
print("MCMC未收敛")
}
plot_mcmc_diagnostic <- function(beta_samples) {
# Extract MCMC samples
#u_samples <- results$u
#sigma_u_samples <- results$sigma_u
par(mfrow=c(3,3))
# Trace plot
for (param in 1:ncol(beta_samples)) {
plot(beta_samples[, param], type = "l", ylab = paste("beta[", param, "]"), col = "blue")
}
par(mfrow=c(3,3))
# ACF plot
for (param in 1:ncol(beta_samples)) {
acf(beta_samples[, param], main = paste("ACF of beta[", param, "] "), col = "blue",xlim=c(1,50))
}
par(mfrow=c(3,3))
# histogram plot
for (param in 1:ncol(beta_samples)) {
hist(beta_samples[, param], main = paste("Histogram of beta[", param, "] "), col = "blue")
}
# Gelman-Rubin statistic
#gr_diag_beta <- gelman.diag(beta_samples)
#gr_diag_u <- gelman.diag(u_samples)
#gr_diag_sigma_u <- gelman.diag(sigma_u_samples)
#cat("Gelman-Rubin diagnostics for beta:\n")
#print(gr_diag_beta)
#cat("\nGelman-Rubin diagnostics for u:\n")
#print(gr_diag_u)
#cat("\nGelman-Rubin diagnostics for sigma_u:\n")
#print(gr_diag_sigma_u)
}
# Run the function with your MCMC results
iter <- 2500
beta_samples <- beta_samples[(iter/2+1):iter,]
